{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十三次课后练习 （选做）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**负责助教：朱轩宇**\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">请将作业文件命名为 第十三次课后练习-选做题+姓名+学号.ipynb, 例如 第十三次课后练习-选做题+张三+1000000000.ipynb</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 红楼梦人物关系网络分析\n",
    "\n",
    "## 引言\n",
    "《红楼梦》作为中国古典文学巅峰之作，其复杂的人物关系网络蕴含着深刻的社会学价值。在实验中，我们运用复杂网络分析方法，构建包含**宁荣两府核心人物及关联家族**的多层网络，揭示隐藏的社会结构和权力分布。\n",
    "\n",
    "\n",
    "## 实验步骤\n",
    "1. 数据预处理\n",
    "   - 使用pandas读取数据文件，并进行数据清洗和预处理，包括去除重复值、关系权重映射等。\n",
    "2. 多层网络构建\n",
    "   1. 使用MultiDiGraph同时记录核心人物关系和家族间关系\n",
    "3. 社区划分\n",
    "   1. **Louvain算法**：基于模块度优化，公式：\n",
    "      $$\n",
    "      Q = \\frac{1}{2m}\\sum_{ij}\\left[A_{ij} - \\frac{k_ik_j}{2m}\\right]\\delta(c_i,c_j)\n",
    "      $$\n",
    "      其中$m$为总边数，$k_i$节点i的度，$c_i$社区划分\n",
    "\n",
    "   2. **LPA算法**：异步标签传播流程：\n",
    "      ```python\n",
    "      while 标签未稳定:\n",
    "          随机选取节点 → 统计邻居标签 → 更新为最多数标签\n",
    "      ```\n",
    "4. 阶层划分\n",
    "   - 方案A：基于度中心性, 介数中心性, 特征向量中心性等作为特征，使用聚类算法进行阶层划分\n",
    "   - 方案B：指定少量阶层代表人物（如：高、中、低分别不超过5个），可以选取度数较高的代表，然后采用合理的算法（聚类-分类=社区划分等）实现人物的阶层自动标注。人工标注测试集（每个阶层不少于10个），评测算法的结果并进行分析。算法合理且分析报告内容比较深入的可获得+1分。\n",
    "   - 方案C：指定少量阶层代表人物（如：高、中、低分别不超过5个），可以选取代表性高的人物。例如地位最高的，地位中间的，地位最低的，也可以选取度数比较高的，利用父子-姐妹-主仆等已知信息，采用合理算法实现更好的人物阶层标注，并对算法结果进行对比评测。算法合理且分析报告内容比较深入的可获得+1到2分。\n",
    "   - 方案D：参考红楼梦文本，在方案C的基础上给出进一步的优化。算法合理且分析报告内容比较深入的可获得+1到3分。\n",
    "   \n",
    "   阶层划分不一定局限于3层，也可以多层。\n",
    "\n",
    "**可能需要额外安装使用的库**\n",
    "\n",
    "- pip install community\n",
    "- pip install python-louvain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import community.community_louvain as community_louvain \n",
    "from networkx.algorithms import community as nx_comm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "\n",
    "# 解决中文显示问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 数据预处理 ==================\n",
    "# 原始数据，读取relation.txt文件\n",
    "with open('relation.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_data = f.read()\n",
    "\n",
    "# 转换为DataFrame\n",
    "lines = [line.split(',') for line in raw_data.strip().split('\\n')]\n",
    "df = pd.DataFrame(lines, columns=['人物A','人物B','关系类型','家族A','家族B'])\n",
    "\n",
    "# 去重处理\n",
    "df = df.drop_duplicates(subset=['人物A', '人物B']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关系权重映射 (1-5分，5分表示关系最紧密/重要)\n",
    "relation_weights = {\n",
    "    # 直系血亲关系 (5分)\n",
    "    '父亲': 5, '父': 5, '母亲': 5, '母': 5, '儿子': 5, '女儿': 5,\n",
    "    '爷爷': 5, '奶奶': 5, '外祖母': 5,\n",
    "    \n",
    "    # 婚姻关系 (4分)\n",
    "    '丈夫': 4, '妻': 4, '夫妻': 4, '妾': 4, '二夫人': 4, '婆婆': 4,\n",
    "    \n",
    "    # 近亲关系 (3-4分)\n",
    "    '兄弟': 4, '姐妹': 4, '哥哥': 4, '弟弟': 4, '姐姐': 4, '妹妹': 4, '胞妹': 4,\n",
    "    '侄女': 3, '侄儿': 3, '孙子': 3, '孙女': 3, '外孙女': 3,\n",
    "    '嫂子': 3, '女婿': 3, '儿媳': 3, '大儿媳': 3, '小儿媳': 3,\n",
    "    \n",
    "    # 远亲/姻亲关系 (2-3分) \n",
    "    '姑母': 3, '岳父': 3, '岳母': 3, '伯父': 3,\n",
    "    '表兄妹': 2, '姑舅哥哥': 2, '兄妹': 2, '内侄女': 2,\n",
    "    \n",
    "    # 特殊亲情关系 (3分)\n",
    "    '养父': 3, '养子': 3, '乳母': 3, '乾娘': 3, '被抚养': 3, \n",
    "    \n",
    "    # 友情关系 (2分)\n",
    "    '朋友': 2, '好友': 2, '好朋友': 2, '好兄弟': 2, '相好': 2,\n",
    "    \n",
    "    # 暧昧关系 (2分)\n",
    "    '暧昧': 2,\n",
    "    \n",
    "    # 主仆/服侍关系 (1-2分)\n",
    "    '主人': 2, '老奴': 1, '买办': 1, '小厮': 1,\n",
    "    '丫环': 1, '丫头': 1, '大丫环': 1, '大丫头': 1, '陪房': 1, '陪房丫头': 1,\n",
    "    \n",
    "    # 其他关系 (2分)\n",
    "    '老师': 2, '二房': 2\n",
    "}\n",
    "\n",
    "# 为缺失的关系类型设置默认权重\n",
    "default_weight = 1\n",
    "#######################\n",
    "# 应用权重映射到数据框\n",
    "df['weight'] = df['关系类型'].map(relation_weights).fillna(default_weight)\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建多层网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**单层网络**是传统网络模型的基本形式，由单一类型的节点和单一类型的边构成。边表示节点间存在某种统一的关系。例如，一个简单的社交网络中，边仅表示\"是否为朋友\"这一种关系。\n",
    "\n",
    "**多层网络**则允许在同一个网络中表示多种不同类型的关系，每一层代表一种特定类型的关系。在红楼梦分析中，我们看到了两个层次：\n",
    "\n",
    "- 核心关系层：人物之间的直接关系（如亲属、主仆等）\n",
    "- 家族桥梁层：家族之间的关系\n",
    "\n",
    "在红楼梦人物关系分析中，多层网络具有以下优势：\n",
    "\n",
    "1. 关系表达更丰富\n",
    "2. 节点分类更清晰\n",
    "3. 分析更加系统\n",
    "    - 可以分析家族内部结构与家族间联系\n",
    "    - 可以探索人物社会地位与家族背景的关系\n",
    "    - 能够研究不同关系类型对社区形成的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 构建多层网络 ==================\n",
    "# 创建多重有向图以支持多层网络\n",
    "G = nx.MultiDiGraph(name=\"RedMansion\")\n",
    "\n",
    "# 添加人物关系层（核心层）\n",
    "for _, row in df.iterrows():\n",
    "    #######################\n",
    "    # 添加人物关系边，保留所有关系属性\n",
    "    # 参数：layer='核心关系'，表示该边属于核心关系层\n",
    "    # 参数：weight=row['weight']，表示该边的权重\n",
    "    # 参数：relation_type=row['关系类型']，表示该边的关系类型\n",
    "    G.add_edge(row['人物A'], row['人物B'], \n",
    "               layer='核心关系',\n",
    "               weight=row['weight'],\n",
    "               relation_type=row['关系类型'])\n",
    "    #######################\n",
    "    \n",
    "    # 同时记录人物所属家族信息\n",
    "    if row['人物A'] not in G.nodes() or 'family' not in G.nodes[row['人物A']]:\n",
    "        G.nodes[row['人物A']]['family'] = row['家族A']\n",
    "    \n",
    "    if row['人物B'] not in G.nodes() or 'family' not in G.nodes[row['人物B']]:\n",
    "        G.nodes[row['人物B']]['family'] = row['家族B']\n",
    "\n",
    "# 添加家族桥梁层（家族间的联系）\n",
    "family_connections = set()  # 用于跟踪已添加的家族连接\n",
    "for _, row in df.iterrows():\n",
    "    # 仅当两个家族不同时添加家族间连接\n",
    "    if row['家族A'] != row['家族B'] and (row['家族A'], row['家族B']) not in family_connections:\n",
    "        G.add_edge(row['家族A'], row['家族B'],\n",
    "                  layer='家族桥梁',\n",
    "                  weight=0.5)  # 家族间连接权重较低，表示是抽象关系\n",
    "        family_connections.add((row['家族A'], row['家族B']))\n",
    "        family_connections.add((row['家族B'], row['家族A']))  # 避免重复添加反向连接\n",
    "        \n",
    "        # 标记节点类型为家族\n",
    "        G.nodes[row['家族A']]['type'] = 'family'\n",
    "        G.nodes[row['家族B']]['type'] = 'family'\n",
    "\n",
    "# 标记所有人物节点类型\n",
    "for node in G.nodes():\n",
    "    if 'type' not in G.nodes[node]:\n",
    "        G.nodes[node]['type'] = 'character'\n",
    "\n",
    "# 输出网络基本信息\n",
    "print(f\"构建完成的红楼梦人物关系网络:\")\n",
    "print(f\"- 总节点数: {G.number_of_nodes()}\")\n",
    "print(f\"- 总边数: {G.number_of_edges()}\")\n",
    "print(f\"- 其中人物节点: {sum(1 for _, attr in G.nodes(data=True) if attr.get('type')=='character')}\")\n",
    "print(f\"- 其中家族节点: {sum(1 for _, attr in G.nodes(data=True) if attr.get('type')=='family')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 社区发现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现通过Louvain算法和标签传播算法(LPA)对红楼梦人物关系网络进行社区划分，代码首先创建一个只包含人物关系的无向图，然后使用两种算法进行社区发现，计算并比较它们的模块度，最后分析并展示了主要社区的核心成员。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 社区发现算法原理\n",
    "\n",
    "#### Louvain 算法\n",
    "\n",
    "Louvain 算法是一种基于模块度优化的社区发现方法，以比利时鲁汶大学命名。该算法通过贪心优化模块度 Q 来识别网络中的社区结构。\n",
    "\n",
    "##### 主要原理\n",
    "\n",
    "1. **模块度定义**：\n",
    "   $$Q = \\frac{1}{2m}\\sum_{ij}\\left[A_{ij} - \\frac{k_i k_j}{2m}\\right]\\delta(c_i,c_j)$$\n",
    "   其中，$m$ 是网络中的总边数，$A_{ij}$ 是节点 $i$ 和 $j$ 之间的边权重，$k_i$ 和 $k_j$ 是节点 $i$ 和 $j$ 的度，$\\delta(c_i,c_j)$ 表示如果节点 $i$ 和 $j$ 在同一社区则为 1，否则为 0。\n",
    "\n",
    "2. **算法流程**：\n",
    "   - **阶段一**：将每个节点初始化为单独的社区，然后逐个考察节点，计算将其移动到相邻社区后的模块度增益，选择使增益最大的移动操作。\n",
    "   - **阶段二**：将第一阶段形成的社区作为新的\"超级节点\"，构建一个新的网络，其中两个超级节点之间的边权重为原社区间所有节点对之间边的权重和。\n",
    "   - 重复这两个阶段，直到模块度不再增加。\n",
    "\n",
    "3. **参数控制**：\n",
    "   - `resolution`：控制识别社区的粒度，较大的值会产生更多较小的社区，较小的值则产生较少的大社区。\n",
    "\n",
    "##### 优势与局限\n",
    "\n",
    "- **优势**：\n",
    "  - 计算效率高，尤其适合处理大规模网络\n",
    "  - 能自动确定社区数量\n",
    "  - 能够发现多层次的社区结构\n",
    "\n",
    "- **局限**：\n",
    "  - 存在分辨率限制，可能无法检测到非常小的社区\n",
    "  - 由于贪心策略，可能陷入局部最优解\n",
    "\n",
    "#### 标签传播算法 (LPA)\n",
    "\n",
    "标签传播算法是一种基于信息传播思想的社区发现方法，通过模拟节点间的标签传递过程来识别网络社区。\n",
    "\n",
    "##### 主要原理\n",
    "\n",
    "1. **初始化**：\n",
    "   - 为每个节点分配一个唯一的标签（或利用已有的结构信息，如在红楼梦分析中使用家族信息）\n",
    "\n",
    "2. **传播过程**：\n",
    "   ```python\n",
    "   while 标签未稳定:\n",
    "       随机选取节点\n",
    "       统计该节点邻居的标签频率\n",
    "       将节点更新为邻居中最常见的标签（如有多个频率相同的标签则随机选择）\n",
    "   ```\n",
    "\n",
    "3. **异步更新机制**：\n",
    "   - 即时更新节点标签，使新标签可以立即影响后续节点的标签更新\n",
    "   - 这种更新方式使得标签能够更快地在网络中传播\n",
    "\n",
    "##### 优势与局限\n",
    "\n",
    "- **优势**：\n",
    "  - 算法简单直观，时间复杂度近似线性\n",
    "  - 不需要预设社区数量\n",
    "  - 适合处理大规模网络\n",
    "\n",
    "- **局限**：\n",
    "  - 结果受节点处理顺序影响，可能不稳定\n",
    "  - 可能出现\"标签震荡\"现象，难以收敛\n",
    "  - 在某些网络中，可能导致单一巨大社区的形成（标签同质化）\n",
    "\n",
    "##### 改进策略\n",
    "\n",
    "红楼梦网络分析中采用了一些LPA的改进策略：\n",
    "- 使用家族信息作为初始标签，提供更有意义的起始点\n",
    "- 结合边权重信息指导标签传播过程\n",
    "\n",
    "两种算法在红楼梦人物关系网络分析中的表现可以通过其模块度值进行比较，通常Louvain算法会获得较高的模块度值，而LPA则在速度和可扩展性方面具有优势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 社区发现 ==================\n",
    "print(\"开始进行社区发现算法...\")\n",
    "\n",
    "# 原始有向多重图可能包含家族节点和人物节点，为了更精确的社区划分，\n",
    "# 创建只包含人物关系的无向图\n",
    "G_undir = nx.Graph()\n",
    "\n",
    "# 只添加人物节点及其关系\n",
    "character_nodes = [node for node, attr in G.nodes(data=True) if attr.get('type') == 'character']\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if u in character_nodes and v in character_nodes:\n",
    "        # 如果边已存在，使用最大权重\n",
    "        if G_undir.has_edge(u, v):\n",
    "            G_undir[u][v]['weight'] = max(G_undir[u][v].get('weight', 0), data.get('weight', 1))\n",
    "        else:\n",
    "            G_undir.add_edge(u, v, weight=data.get('weight', 1))\n",
    "\n",
    "print(f\"社区划分网络构建完成，包含 {len(G_undir.nodes())} 个节点和 {len(G_undir.edges())} 条边\")\n",
    "\n",
    "# 1. Louvain算法 - 基于模块度优化的社区发现\n",
    "print(\"执行Louvain算法...\")\n",
    "# resolution参数控制社区大小，较大的值会产生更多较小的社区\n",
    "#######################\n",
    "# 使用louvain算法实现社区发现\n",
    "partition_louvain = community_louvain.best_partition(G_undir, weight='weight')\n",
    "#######################\n",
    "\n",
    "# 计算Louvain社区数量\n",
    "louvain_communities = len(set(partition_louvain.values()))\n",
    "print(f\"Louvain算法发现了 {louvain_communities} 个社区\")\n",
    "\n",
    "# 2. 标签传播算法 (LPA) - 模拟信息传播过程\n",
    "print(\"执行标签传播算法(LPA)...\")\n",
    "#######################\n",
    "# 使用标签传播算法实现社区发现\n",
    "# 初始化节点标签，使用节点所属家族哈希值作为初始标签，提供一些结构信息，如果没有家族信息，使用节点名称的哈希值\n",
    "for node in G_undir.nodes():\n",
    "    family = G.nodes[node].get('family', None)\n",
    "    if family:\n",
    "        G_undir.nodes[node]['label'] = hash(family)\n",
    "    else:\n",
    "        G_undir.nodes[node]['label'] = hash(node)\n",
    "\n",
    "\n",
    "# 执行异步标签传播算法\n",
    "communities_lpa = list(nx.community.asyn_lpa_communities(G_undir, weight='weight'))\n",
    "#####################\n",
    "\n",
    "print(f\"标签传播算法发现了 {len(communities_lpa)} 个社区\")\n",
    "\n",
    "# 计算社区划分的模块度\n",
    "louvain_modularity = nx_comm.modularity(G_undir, \n",
    "                                      [{n for n, c in partition_louvain.items() if c == i} \n",
    "                                       for i in set(partition_louvain.values())])\n",
    "\n",
    "# 转换LPA结果以计算模块度\n",
    "lpa_communities_sets = [set(community) for community in communities_lpa]\n",
    "lpa_modularity = nx_comm.modularity(G_undir, lpa_communities_sets)\n",
    "\n",
    "print(f\"Louvain算法模块度: {louvain_modularity:.4f}\")\n",
    "print(f\"标签传播算法模块度: {lpa_modularity:.4f}\")\n",
    "\n",
    "# 分析主要社区的核心成员\n",
    "print(\"\\n====== 主要社区的核心成员 ======\")\n",
    "community_sizes = {}\n",
    "for comm_id in set(partition_louvain.values()):\n",
    "    members = [node for node, cid in partition_louvain.items() if cid == comm_id]\n",
    "    community_sizes[comm_id] = len(members)\n",
    "    \n",
    "# 显示最大的几个社区\n",
    "largest_communities = sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for comm_id, size in largest_communities:\n",
    "    # 获取该社区的所有成员\n",
    "    members = [node for node, cid in partition_louvain.items() if cid == comm_id]\n",
    "    \n",
    "    # 计算社区内节点的度中心性，找出核心人物\n",
    "    subgraph = G_undir.subgraph(members)\n",
    "    degree_cent = nx.degree_centrality(subgraph)\n",
    "    \n",
    "    # 获取前3个中心人物\n",
    "    core_members = sorted(degree_cent.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    core_names = [name for name, _ in core_members]\n",
    "    \n",
    "    print(f\"社区 {comm_id} (成员数: {size}): 核心人物 - {', '.join(core_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# 可视化两个算法的社区划分\n",
    "def plot_communities(G, partition, title):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    pos = nx.spring_layout(G, seed=42, k=0.3)  # 增大k值使节点更分散\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    communities = set(partition.values())\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(communities)))\n",
    "    cmap = {cid: colors[i] for i, cid in enumerate(communities)}\n",
    "    \n",
    "    # 绘制边\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.1)\n",
    "    \n",
    "    # 绘制节点（按社区）\n",
    "    for cid in communities:\n",
    "        nodes = [n for n in G.nodes() if partition[n] == cid]\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=nodes, \n",
    "                             node_color=[cmap[cid] for _ in nodes],\n",
    "                             node_size=50, label=f'社区 {cid}')\n",
    "    \n",
    "    # 标注关键节点（度中心性前5）\n",
    "    degree_cent = nx.degree_centrality(G)\n",
    "    top_nodes = sorted(degree_cent, key=degree_cent.get, reverse=True)[:5]\n",
    "    labels = {n: n for n in top_nodes}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=10)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#####################\n",
    "\n",
    "# 显示Louvain算法的社区划分\n",
    "plot_communities(G_undir, partition_louvain, \"红楼梦人物关系网络 - Louvain算法社区划分\")\n",
    "\n",
    "# 为了比较，也可以可视化LPA的结果\n",
    "# 先将LPA结果转换为与Louvain结果相同的格式\n",
    "partition_lpa = {}\n",
    "for i, community in enumerate(communities_lpa):\n",
    "    for node in community:\n",
    "        partition_lpa[node] = i\n",
    "\n",
    "plot_communities(G_undir, partition_lpa, \"红楼梦人物关系网络 - LPA算法社区划分\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 阶层划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考引言部分，阶层划分可以基于不同的方案实现，下文提供的是方案A实现的样例\n",
    "   - 方案A：基于度中心性, 介数中心性, 特征向量中心性等作为特征，使用聚类算法进行阶层划分\n",
    "   - 方案B：指定少量阶层代表人物（如：高、中、低分别不超过5个），可以选取度数较高的代表，然后采用合理的算法（聚类-分类=社区划分等）实现人物的阶层自动标注。人工标注测试集（每个阶层不少于10个），评测算法的结果并进行分析。算法合理且分析报告内容比较深入的可获得+1分。\n",
    "   - 方案C：指定少量阶层代表人物（如：高、中、低分别不超过5个），可以选取代表性高的人物。例如地位最高的，地位中间的，地位最低的，也可以选取度数比较高的，利用父子-姐妹-主仆等已知信息，采用合理算法实现更好的人物阶层标注，并对算法结果进行对比评测。算法合理且分析报告内容比较深入的可获得+1到2分。\n",
    "   - 方案D：参考红楼梦文本，在方案C的基础上给出进一步的优化。算法合理且分析报告内容比较深入的可获得+1到3分。\n",
    "   \n",
    "   阶层划分不一定局限于3层，也可以多层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样例方案A实现：\n",
    "\n",
    "阶层划分实现基于网络中心性指标的人物社会阶层分析，首先计算人物节点的度中心性、介数中心性、特征向量中心性和接近中心性四种指标，然后使用层次聚类算法将人物划分为上中下三个阶层，最后分析各阶层的核心成员和家族分布情况，并通过三维散点图和网络图两种方式可视化阶层划分结果。\n",
    "\n",
    "### 实现原理\n",
    "1. 中心性指标计算：中心性指标是衡量节点在网络中重要性的关键指标，代码计算了四种常用的中心性指标\n",
    "2. 特征矩阵构建与标准化：将四种中心性指标组合成特征矩阵，并进行标准化处理以消除量纲差异\n",
    "3. 层次聚类实现阶层划分：使用层次聚类算法(Agglomerative Clustering)将人物划分为三个阶层\n",
    "4. 层标签映射与排序：代码通过计算每个聚类的平均中心性，将聚类标签映射为有意义的阶层名称\n",
    "5. 结果分析与可视化：代码分析了各阶层的核心成员和家族分布情况\n",
    "\n",
    "这种基于中心性指标的多维聚类分析，能够客观地根据人物在关系网络中的位置和影响力进行阶层划分，揭示了《红楼梦》中人物社会地位的分层结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 阶层划分 ==================\n",
    "# 计算各种中心性指标\n",
    "centrality_metrics = {}\n",
    "\n",
    "# 仅使用人物节点(过滤掉家族节点)\n",
    "character_nodes = [node for node in G_undir.nodes() if node in df['人物A'].values or node in df['人物B'].values]\n",
    "character_subgraph = G_undir.subgraph(character_nodes)\n",
    "\n",
    "print(f\"计算中心性指标中，共 {len(character_nodes)} 个人物节点...\")\n",
    "#######################\n",
    "# 计算各种中心性指标\n",
    "# 计算度中心性\n",
    "centrality_metrics['degree'] = nx.degree_centrality(character_subgraph)\n",
    "\n",
    "# 计算介数中心性 (可能计算较慢)\n",
    "centrality_metrics['betweenness'] = nx.betweenness_centrality(character_subgraph, weight='weight', normalized=True)\n",
    "\n",
    "# 计算特征向量中心性\n",
    "centrality_metrics['eigenvector'] = nx.eigenvector_centrality(character_subgraph, max_iter=1000, weight='weight')\n",
    "\n",
    "# 计算接近中心性\n",
    "centrality_metrics['closeness'] = nx.closeness_centrality(character_subgraph)\n",
    "#######################\n",
    "\n",
    "# 创建特征矩阵用于聚类\n",
    "features = []\n",
    "character_names = []\n",
    "\n",
    "for node in character_nodes:\n",
    "    # 收集节点的所有中心性指标作为特征\n",
    "    node_features = [\n",
    "        centrality_metrics['degree'].get(node, 0),\n",
    "        centrality_metrics['betweenness'].get(node, 0),\n",
    "        centrality_metrics['eigenvector'].get(node, 0),\n",
    "        centrality_metrics['closeness'].get(node, 0)\n",
    "    ]\n",
    "    features.append(node_features)\n",
    "    character_names.append(node)\n",
    "\n",
    "# 特征标准化(使各特征量纲一致)\n",
    "features_array = np.array(features)\n",
    "features_mean = np.mean(features_array, axis=0)\n",
    "features_std = np.std(features_array, axis=0)\n",
    "features_scaled = (features_array - features_mean) / features_std\n",
    "\n",
    "#######################\n",
    "# 使用层次聚类算法进行阶层划分\n",
    "# 使用层次聚类算法，分为3个阶层: 上层/中上层/中下层\n",
    "n_clusters = 3  \n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=n_clusters,\n",
    "    linkage='ward'           # ward 方法在欧氏距离上效果最好\n",
    ")\n",
    "# 获取聚类结果\n",
    "labels = clustering.fit_predict(features_scaled)\n",
    "#########################\n",
    "\n",
    "# 创建包含聚类结果的DataFrame\n",
    "hierarchy_df = pd.DataFrame({\n",
    "    '人物': character_names,\n",
    "    '阶层': labels,\n",
    "    '度中心性': [centrality_metrics['degree'].get(node, 0) for node in character_names],\n",
    "    '介数中心性': [centrality_metrics['betweenness'].get(node, 0) for node in character_names],\n",
    "    '特征向量中心性': [centrality_metrics['eigenvector'].get(node, 0) for node in character_names],\n",
    "    '接近中心性': [centrality_metrics['closeness'].get(node, 0) for node in character_names]\n",
    "})\n",
    "\n",
    "# 添加家族信息\n",
    "hierarchy_df['家族'] = hierarchy_df['人物'].map(\n",
    "    lambda x: G.nodes[x].get('family', '未知') if x in G.nodes else '未知'\n",
    ")\n",
    "\n",
    "# 将阶层标签映射为更有意义的名称\n",
    "hierarchy_map = {}\n",
    "avg_centrality_by_class = {}\n",
    "\n",
    "# 计算每个阶层的平均中心性指标\n",
    "for i in range(n_clusters):\n",
    "    class_data = hierarchy_df[hierarchy_df['阶层'] == i]\n",
    "    avg_centrality = class_data['度中心性'].mean() + class_data['特征向量中心性'].mean()\n",
    "    avg_centrality_by_class[i] = avg_centrality\n",
    "\n",
    "# 根据平均中心性由高到低排序阶层\n",
    "sorted_classes = sorted(avg_centrality_by_class.items(), key=lambda x: x[1], reverse=True)\n",
    "hierarchy_names = ['上层', '中层', '下层']\n",
    "\n",
    "# 映射聚类标签到阶层名称\n",
    "for i, (class_id, _) in enumerate(sorted_classes):\n",
    "    hierarchy_map[class_id] = hierarchy_names[i]\n",
    "\n",
    "# 更新DataFrame中的阶层标签\n",
    "hierarchy_df['阶层名称'] = hierarchy_df['阶层'].map(hierarchy_map)\n",
    "\n",
    "# 排序并显示结果\n",
    "print(\"\\n==== 人物阶层划分结果 ====\")\n",
    "sorted_hierarchy = hierarchy_df.sort_values(by=['阶层', '度中心性'], ascending=[True, False])\n",
    "print(sorted_hierarchy[['人物', '阶层名称', '家族', '度中心性']].head(15))\n",
    "\n",
    "# 分析每个阶层的主要人物\n",
    "print(\"\\n==== 各阶层核心人物 ====\")\n",
    "for hierarchy_name in hierarchy_names:\n",
    "    top_chars = hierarchy_df[hierarchy_df['阶层名称'] == hierarchy_name].nlargest(3, '度中心性')\n",
    "    print(f\"{hierarchy_name}:\", \", \".join(top_chars['人物'].values))\n",
    "\n",
    "# 统计不同阶层在不同家族中的分布\n",
    "family_hierarchy_counts = pd.crosstab(\n",
    "    hierarchy_df['家族'], \n",
    "    hierarchy_df['阶层名称'],\n",
    "    normalize='index'  # 按行标准化，显示每个家族中不同阶层的比例\n",
    ")\n",
    "\n",
    "# 显示结果\n",
    "print(\"\\n==== 家族内阶层分布 ====\")\n",
    "print(family_hierarchy_counts)\n",
    "\n",
    "# 将结果存储为变量供后续可视化使用\n",
    "cross_tab = family_hierarchy_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图节点可视化不同阶层\n",
    "def plot_hierarchy_3d(hierarchy_df, title):\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 使用不同的颜色和形状表示不同的阶层\n",
    "    colors = ['r', 'g', 'b']\n",
    "    markers = ['o', '^', 's']\n",
    "\n",
    "    for i, hierarchy_name in enumerate(hierarchy_names):\n",
    "        class_data = hierarchy_df[hierarchy_df['阶层名称'] == hierarchy_name]\n",
    "        x = class_data['度中心性']\n",
    "        y = class_data['介数中心性']\n",
    "        z = class_data['特征向量中心性']\n",
    "        \n",
    "        ax.scatter(x, y, z, \n",
    "                   c=colors[i], \n",
    "                   marker=markers[i], \n",
    "                   label=hierarchy_name, \n",
    "                   alpha=0.6, \n",
    "                   edgecolors='w', \n",
    "                   s=100)  # 调整点的大小\n",
    "\n",
    "    ax.set_xlabel('度中心性')\n",
    "    ax.set_ylabel('介数中心性')\n",
    "    ax.set_zlabel('特征向量中心性')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 创建一个更直观的可视化，同时突出关键人物\n",
    "def plot_network_hierarchy(G_undir, hierarchy_df, important_people):\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # 使用Fruchterman-Reingold布局算法\n",
    "    pos = nx.spring_layout(G_undir, seed=42, k=0.3)\n",
    "    \n",
    "    # 定义每个阶层节点的大小\n",
    "    node_sizes = {'上层': 250, '中层': 150, '下层': 80}\n",
    "    \n",
    "    # 绘制所有边\n",
    "    nx.draw_networkx_edges(G_undir, pos, alpha=0.2, width=0.5)\n",
    "    \n",
    "    # 绘制家族节点\n",
    "    family_nodes = [node for node, attr in G.nodes(data=True) \n",
    "                    if attr.get('type') == 'family' and node in G_undir.nodes()]\n",
    "    if family_nodes:\n",
    "        nx.draw_networkx_nodes(G_undir, pos, \n",
    "                              nodelist=family_nodes,\n",
    "                              node_color='gray',\n",
    "                              alpha=0.8,\n",
    "                              node_size=200,\n",
    "                              label='家族')\n",
    "    \n",
    "    # 绘制各阶层人物节点\n",
    "    for i, level in enumerate(['上层', '中层', '下层']):\n",
    "        level_data = hierarchy_df[hierarchy_df['阶层名称'] == level]\n",
    "        nodes = level_data['人物'].tolist()\n",
    "        valid_nodes = [n for n in nodes if n in G_undir.nodes()]\n",
    "        \n",
    "        if valid_nodes:\n",
    "            nx.draw_networkx_nodes(G_undir, pos,\n",
    "                                  nodelist=valid_nodes,\n",
    "                                  node_color=['crimson', 'green', 'royalblue'][i],\n",
    "                                  node_size=node_sizes[level],\n",
    "                                  alpha=0.7,\n",
    "                                  label=f'{level}人物 ({len(valid_nodes)}人)')\n",
    "    \n",
    "    # 标注重要人物\n",
    "    important_labels = {node: node for node in important_people if node in G_undir.nodes()}\n",
    "    nx.draw_networkx_labels(G_undir, pos, \n",
    "                           labels=important_labels,\n",
    "                           font_size=10,\n",
    "                           font_weight='bold',\n",
    "                           font_color='black')\n",
    "    \n",
    "    plt.title('红楼梦人物关系网络 - 阶层划分', fontsize=16)\n",
    "    plt.legend(scatterpoints=1, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 核心人物\n",
    "important_people = ['贾母', '王熙凤', '贾宝玉', '林黛玉', '薛宝钗', \n",
    "                   '贾政', '贾珍', '秦可卿', '贾惜春']\n",
    "\n",
    "# 可视化三维特征空间中的阶层划分\n",
    "plot_hierarchy_3d(hierarchy_df, \"红楼梦人物阶层划分 - 3D可视化\")\n",
    "\n",
    "# 可视化网络中的阶层分布\n",
    "plot_network_hierarchy(G_undir, hierarchy_df, important_people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scheme D: 综合文本挖掘与社交网络中心性\n",
    "\"\"\"\n",
    "import jieba\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "import networkx as nx\n",
    "\n",
    "# -------- 1. 读取关系数据并构建社交网络 --------\n",
    "# 读取 relation.txt\n",
    "df = pd.read_csv('relation.txt', names=['人物A','人物B','关系类型','家族A','家族B'], encoding='utf-8')\n",
    "# 使用之前定义的 relation_weights 映射权重\n",
    "default_weight = 1\n",
    "df['weight'] = df['关系类型'].map(relation_weights).fillna(default_weight)\n",
    "\n",
    "# 构建无向人物网络 G_undir\n",
    "G_multi = nx.MultiDiGraph()\n",
    "for _, row in df.iterrows():\n",
    "    G_multi.add_edge(row['人物A'], row['人物B'], weight=row['weight'])\n",
    "# 只保留人物节点构建 G_undir\n",
    "character_nodes = pd.unique(df[['人物A','人物B']].values.ravel())\n",
    "G_undir = nx.Graph()\n",
    "for u, v, data in G_multi.edges(data=True):\n",
    "    if u in character_nodes and v in character_nodes:\n",
    "        w = data['weight']\n",
    "        if G_undir.has_edge(u, v):\n",
    "            G_undir[u][v]['weight'] = max(G_undir[u][v]['weight'], w)\n",
    "        else:\n",
    "            G_undir.add_edge(u, v, weight=w)\n",
    "\n",
    "# 过滤得到人物子图\n",
    "character_subgraph = G_undir.subgraph(character_nodes)\n",
    "\n",
    "# -------- 2. 计算社交网络中心性特征 --------\n",
    "centrality_metrics = {}\n",
    "centrality_metrics['degree'] = nx.degree_centrality(character_subgraph)\n",
    "centrality_metrics['betweenness'] = nx.betweenness_centrality(character_subgraph, weight='weight', normalized=True)\n",
    "centrality_metrics['eigenvector'] = nx.eigenvector_centrality(character_subgraph, weight='weight', max_iter=1000)\n",
    "centrality_metrics['closeness'] = nx.closeness_centrality(character_subgraph)\n",
    "\n",
    "# 构建原网络特征DataFrame\n",
    "features_df = pd.DataFrame({\n",
    "    'degree': centrality_metrics['degree'],\n",
    "    'betweenness': centrality_metrics['betweenness'],\n",
    "    'eigenvector': centrality_metrics['eigenvector'],\n",
    "    'closeness': centrality_metrics['closeness']\n",
    "})\n",
    "\n",
    "# -------- 3. 文本挖掘：出现频次与共现网络 --------\n",
    "# 读取小说全文\n",
    "with open('红楼梦-清-曹雪芹.txt', 'r', encoding='gb18030') as f:\n",
    "    text = f.read()\n",
    "# 人物别名映射 (不全就不全就这样吧, 太多啦啊啊啊)\n",
    "character_aliases = {\n",
    "    # --- 主角 ---\n",
    "    '贾宝玉': ['贾宝玉', '宝玉', '宝二爷', '怡红公子', '绛洞花王', '混世魔王', '玉兄', '宝兄弟'],\n",
    "    '林黛玉': ['林黛玉', '黛玉', '林妹妹', '林姑娘', '颦儿', '颦顰', '潇湘妃子'],\n",
    "    '薛宝钗': ['薛宝钗', '宝钗', '宝姐姐', '宝姑娘', '蘅芜君', '薛大姑娘'], \n",
    "\n",
    "    # --- 贾府长辈 ---\n",
    "    '贾母': ['贾母', '老太太', '史太君', '老祖宗'],\n",
    "    '贾赦': ['贾赦', '赦老爹', '赦老爷', '大老爷'],\n",
    "    '邢夫人': ['邢夫人', '大太太'],\n",
    "    '贾政': ['贾政', '政老爹', '政老爷', '老爷'],\n",
    "    '王夫人': ['王夫人', '太太', '二太太'], \n",
    "    '贾敬': ['贾敬', '敬老爷'], \n",
    "\n",
    "    # --- 贾府平辈 ---\n",
    "    '贾琏': ['贾琏', '琏二爷', '琏二哥'],\n",
    "    '王熙凤': ['王熙凤', '凤姐', '凤姐儿', '凤哥儿', '琏二奶奶', '凤辣子'],\n",
    "    '贾元春': ['贾元春', '元春', '元妃', '贵妃', '大姑娘'], \n",
    "    '贾迎春': ['贾迎春', '迎春', '二姑娘', '二小姐', '菱洲'],\n",
    "    '贾探春': ['贾探春', '探春', '三姑娘', '三小姐', '蕉下客', '秋爽斋主'],\n",
    "    '贾惜春': ['贾惜春', '惜春', '四姑娘', '四小姐', '藕榭'],\n",
    "    '李纨': ['李纨', '大奶奶', '大嫂子', '宫裁', '稻香老农'],\n",
    "    '秦可卿': ['秦可卿', '可卿', '可儿', '秦氏', '兼美'], \n",
    "    '贾珍': ['贾珍', '珍大爷', '大爷'], \n",
    "    '尤氏': ['尤氏', '珍大奶奶'], \n",
    "\n",
    "    # --- 贾府晚辈 ---\n",
    "    '贾蓉': ['贾蓉', '蓉儿'],\n",
    "    '贾兰': ['贾兰', '兰儿'],\n",
    "    '贾环': ['贾环', '环老三', '环哥儿'], \n",
    "\n",
    "    # --- 亲戚 ---\n",
    "    '史湘云': ['史湘云', '湘云', '史大姑娘', '云妹妹', '枕霞旧友'],\n",
    "    '薛姨妈': ['薛姨妈', '姨妈'], \n",
    "    '薛蟠': ['薛蟠', '文龙', '薛大爷', '呆霸王'],\n",
    "    '薛蝌': ['薛蝌'],\n",
    "    '薛宝琴': ['薛宝琴', '宝琴'],\n",
    "    '邢岫烟': ['邢岫烟', '岫烟'],\n",
    "    '尤二姐': ['尤二姐', '二姐'],\n",
    "    '尤三姐': ['尤三姐', '三姐'],\n",
    "    '王子腾': ['王子腾'],\n",
    "    \n",
    "    '王仁': ['王仁'], \n",
    "\n",
    "    # --- 重要丫鬟/仆人 ---\n",
    "    '袭人': ['袭人', '花袭人', '珍珠', '蕊珠'],\n",
    "    '晴雯': ['晴雯', '雯儿'],\n",
    "    '麝月': ['麝月'],\n",
    "    '秋纹': ['秋纹'],\n",
    "    '碧痕': ['碧痕'],\n",
    "    '紫鹃': ['紫鹃', '鹦哥'], \n",
    "    '雪雁': ['雪雁'], \n",
    "    '莺儿': ['莺儿', '黄金莺'], \n",
    "    '平儿': ['平儿', '平姑娘'], \n",
    "    '鸳鸯': ['鸳鸯'], \n",
    "    '琥珀': ['琥珀'], \n",
    "    '金钏': ['金钏', '金钏儿'], \n",
    "    '玉钏': ['玉钏', '玉钏儿'], \n",
    "    '司棋': ['司棋'], \n",
    "    '侍书': ['侍书'], \n",
    "    '入画': ['入画'], \n",
    "    '彩云': ['彩云'],\n",
    "    '彩霞': ['彩霞'],\n",
    "    '小红': ['小红', '林红玉', '红玉'],\n",
    "    '茗烟': ['茗烟', '焙茗'], \n",
    "    '李贵': ['李贵'], \n",
    "    '周瑞家的': ['周瑞家的'], \n",
    "    '林之孝家的': ['林之孝家的'], \n",
    "    '赖大家的': ['赖大家的'], \n",
    "    '焦大': ['焦大'], \n",
    "    '傻大姐': ['傻大姐'], \n",
    "\n",
    "    # --- 其他重要人物 ---\n",
    "    '刘姥姥': ['刘姥姥', '刘姥姆'],\n",
    "    '妙玉': ['妙玉', '槛外人', '畸人'],\n",
    "    '香菱': ['香菱', '甄英莲', '英莲', '秋菱'], \n",
    "    '甄士隐': ['甄士隐', '甄费'],\n",
    "    '贾雨村': ['贾雨村', '雨村', '时飞'],\n",
    "    '秦钟': ['秦钟', '鲸卿'], \n",
    "    '柳湘莲': ['柳湘莲', '湘莲', '冷郎君'],\n",
    "    '蒋玉菡': ['蒋玉菡', '琪官'], \n",
    "    '冯渊': ['冯渊'], \n",
    "    '张道士': ['张道士'], \n",
    "    '马道婆': ['马道婆'], \n",
    "    '净虚': ['净虚'],\n",
    "    '智能儿': ['智能儿'], \n",
    "    '甄宝玉': ['甄宝玉']\n",
    "}\n",
    "\n",
    "\n",
    "# 按句分割\n",
    "sentences = re.split(r'[。！？；\\n]', text)\n",
    "# 初始化统计\n",
    "mention_counts = {c:0 for c in character_aliases}\n",
    "cooccur = {(a,b):0 for a in character_aliases for b in character_aliases if a!=b}\n",
    "\n",
    "for sent in sentences:\n",
    "    present = set()\n",
    "    for char, aliases in character_aliases.items():\n",
    "        if any(alias in sent for alias in aliases): present.add(char)\n",
    "    for char in present:\n",
    "        mention_counts[char] += 1\n",
    "    for a in present:\n",
    "        for b in present:\n",
    "            if a!=b: cooccur[(a,b)] += 1\n",
    "\n",
    "# 构建文本共现网络\n",
    "G_text = nx.DiGraph()\n",
    "G_text.add_nodes_from(character_aliases)\n",
    "for (a,b), w in cooccur.items():\n",
    "    if w>0: G_text.add_edge(a,b, weight=w)\n",
    "\n",
    "# 计算文本网络中心性\n",
    "central_text = {\n",
    "    'deg_text': nx.degree_centrality(G_text),\n",
    "    'betw_text': nx.betweenness_centrality(G_text, weight='weight'),\n",
    "    'eig_text': nx.eigenvector_centrality(G_text, weight='weight', max_iter=500),\n",
    "    'clo_text': nx.closeness_centrality(G_text)\n",
    "}\n",
    "# 包括出现频次\n",
    "central_text['freq_text'] = mention_counts\n",
    "\n",
    "# -------- 4. 合并特征与聚类 --------\n",
    "# 将文本特征并入 features_df（对齐索引）\n",
    "for key, mapping in central_text.items():\n",
    "    features_df[key] = pd.Series(mapping)\n",
    "# 丢弃全零行\n",
    "features_df.dropna(how='all', inplace=True)\n",
    "\n",
    "# 标准化后聚类\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features_df.values)\n",
    "n_layers = 3\n",
    "clusterer = AgglomerativeClustering(n_clusters=n_layers, linkage='ward')\n",
    "features_df.dropna(inplace=True)\n",
    "\n",
    "X = scaler.fit_transform(features_df.values)\n",
    "labels = clusterer.fit_predict(X)\n",
    "features_df['pred_layer'] = labels\n",
    "\n",
    "# 映射为层级名称（根据平均中心性手动调整顺序）\n",
    "mapping = {0:'上层',1:'中层',2:'下层'}\n",
    "features_df['layer_name'] = features_df['pred_layer'].map(mapping)\n",
    "\n",
    "# 输出结果示例\n",
    "print(features_df[['layer_name','degree','deg_text','freq_text']].sort_values('layer_name').head())\n",
    "\n",
    "# 保存完整结果\n",
    "features_df.to_csv('scheme_d_hierarchy.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 可视化结果!\n",
    "\n",
    "# —— 1. 三维散点图：度中心性 vs 介数中心性 vs 文本度中心性 —— \n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 选择三个指标，比如 degree, betweenness, deg_text\n",
    "x = features_df['degree']\n",
    "y = features_df['betweenness']\n",
    "z = features_df['deg_text']\n",
    "\n",
    "# 不同层级映射不同颜色\n",
    "color_map = {'上层':'r', '中层':'g', '下层':'b'}\n",
    "colors = features_df['layer_name'].map(color_map)\n",
    "\n",
    "ax.scatter(x, y, z, c=colors, s=50, alpha=0.7)\n",
    "ax.set_xlabel('度中心性')\n",
    "ax.set_ylabel('介数中心性')\n",
    "ax.set_zlabel('文本度中心性')\n",
    "ax.set_title('红楼梦人物阶层——三维特征空间')\n",
    "# 添加图例\n",
    "for layer, col in color_map.items():\n",
    "    ax.scatter([], [], [], c=col, label=layer)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# —— 2. 网络结构可视化：按照层级给节点着色 —— \n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(G_undir, seed=42, k=0.3)\n",
    "\n",
    "# 准备节点颜色列表\n",
    "node_colors = []\n",
    "for n in G_undir.nodes():\n",
    "    if n in features_df.index:\n",
    "        node_colors.append(color_map[features_df.at[n, 'layer_name']])\n",
    "    else:\n",
    "        node_colors.append('gray')  # 如果网络里有但没聚类到的，标灰\n",
    "\n",
    "nx.draw_networkx_edges(G_undir, pos, alpha=0.2, width=0.5)\n",
    "nx.draw_networkx_nodes(G_undir, pos,\n",
    "                       node_color=node_colors,\n",
    "                       node_size=100,\n",
    "                       alpha=0.8)\n",
    "# 只标注度最高的几个关键人物\n",
    "deg_cent = nx.degree_centrality(G_undir)\n",
    "top5 = sorted(deg_cent, key=deg_cent.get, reverse=True)[:5]\n",
    "labels = {n: n for n in top5}\n",
    "nx.draw_networkx_labels(G_undir, pos, labels, font_size=10)\n",
    "\n",
    "plt.title('红楼梦人物网络——阶层分布')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# —— 3. 各层级人物数量柱状图 —— \n",
    "counts = features_df['layer_name'].value_counts().reindex(['上层','中层','下层'])\n",
    "plt.figure(figsize=(6,4))\n",
    "counts.plot(kind='bar')\n",
    "plt.xlabel('阶层')\n",
    "plt.ylabel('人物数')\n",
    "plt.title('各阶层人物数量分布')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
